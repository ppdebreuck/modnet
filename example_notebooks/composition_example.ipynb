{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of experimental band gap\n",
    "\n",
    "This notebooks applies MODNet on the matbench experimental band gap data. It is a good example on how MODNet can be used for a composition only task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matminer.datasets import load_dataset\n",
    "from modnet.models import MODNetModel\n",
    "from modnet.preprocessing import MODData\n",
    "import matplotlib.pyplot as plt \n",
    "from pymatgen.core import Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset import:\n",
    "The matbench_expt_gap dataset contains measured band gaps for 4604 compositions of inorganic semiconductors from Zhuo et al., JPCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "      <th>gap expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ag, Au, S)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Ag, W, Br)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ag, Ge, Pb, S)</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Ag, Ge, Pb, Se)</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Ag, B, Br)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        composition  gap expt\n",
       "0       (Ag, Au, S)      0.00\n",
       "1       (Ag, W, Br)      0.00\n",
       "2   (Ag, Ge, Pb, S)      1.83\n",
       "3  (Ag, Ge, Pb, Se)      1.51\n",
       "4       (Ag, B, Br)      0.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"matbench_expt_gap\")\n",
    "df[\"composition\"] = df[\"composition\"].map(Composition) # maps composition to a pymatgen composition object\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.975951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.445034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gap expt\n",
       "count  4604.000000\n",
       "mean      0.975951\n",
       "std       1.445034\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.812500\n",
       "max      11.700000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa3df2efdc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.hist(df.where(df[\"gap expt\"] == 0)[\"gap expt\"], bins=1, density=False, label=\"Zero band gap\")\n",
    "ax.hist(df.where(df[\"gap expt\"] > 0)[\"gap expt\"], bins=11, density=False, label=\"Non-zero band gap\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xlabel(\"Band gap (eV)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n",
      "2021-03-01 15:52:55,884 - modnet - INFO - Loaded CompositionOnlyFeaturizer featurizer.\n"
     ]
    }
   ],
   "source": [
    "# This instantiates the MODData\n",
    "data = MODData(\n",
    "    materials=df[\"composition\"], # you can provide composition objects to MODData\n",
    "    targets=df[\"gap expt\"], \n",
    "    target_names=[\"gap_expt_eV\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-01 15:52:55,891 - modnet - INFO - Computing features, this can take time...\n",
      "2021-03-01 15:52:55,891 - modnet - INFO - Applying composition featurizers...\n",
      "2021-03-01 15:52:55,897 - modnet - INFO - Applying featurizers (AtomicOrbitals(), AtomicPackingEfficiency(), BandCenter(), ElementFraction(), ElementProperty(data_source=<matminer.utils.data.MagpieData object at 0x7fa3df4db280>,\n",
      "                features=['Number', 'MendeleevNumber', 'AtomicWeight',\n",
      "                          'MeltingT', 'Column', 'Row', 'CovalentRadius',\n",
      "                          'Electronegativity', 'NsValence', 'NpValence',\n",
      "                          'NdValence', 'NfValence', 'NValence', 'NsUnfilled',\n",
      "                          'NpUnfilled', 'NdUnfilled', 'NfUnfilled', 'NUnfilled',\n",
      "                          'GSvolume_pa', 'GSbandgap', 'GSmagmom',\n",
      "                          'SpaceGroupNumber'],\n",
      "                stats=['minimum', 'maximum', 'range', 'mean', 'avg_dev',\n",
      "                       'mode']), IonProperty(), Miedema(ss_types=['min'], struct_types=['inter', 'amor', 'ss']), Stoichiometry(), TMetalFraction(), ValenceOrbital(), YangSolidSolution()) to column 'composition'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad1786701ca43aaa6da448fe717b6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='MultipleFeaturizer'), FloatProgress(value=0.0, max=4604.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-01 16:00:52,973 - modnet - INFO - Data has successfully been featurized!\n"
     ]
    }
   ],
   "source": [
    "# Featurization of the moddata\n",
    "# It will automatically apply composition only featurizers\n",
    "data.featurize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(range(100), test_size=0.1, random_state=1234)\n",
    "train, test = data.split(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-01 16:00:53,015 - modnet - INFO - Computing \"self\" MI (i.e. information entropy) of features\n",
      "2021-03-01 16:00:53,705 - modnet - INFO - Computing cross NMI between all features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [01:31<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-01 16:02:25,262 - modnet - INFO - Starting target 1/1: gap_expt_eV ...\n",
      "2021-03-01 16:02:25,262 - modnet - INFO - Computing mutual information between features and target...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-01 16:02:26,142 - modnet - INFO - Computing optimal features...\n",
      "2021-03-01 16:02:30,027 - modnet - INFO - Selected 50/195 features...\n",
      "2021-03-01 16:02:33,175 - modnet - INFO - Selected 100/195 features...\n",
      "2021-03-01 16:02:35,527 - modnet - INFO - Selected 150/195 features...\n",
      "2021-03-01 16:02:37,074 - modnet - INFO - Done with target 1/1: gap_expt_eV.\n",
      "2021-03-01 16:02:37,074 - modnet - INFO - Merging all features...\n",
      "2021-03-01 16:02:37,075 - modnet - INFO - Done.\n"
     ]
    }
   ],
   "source": [
    "train.feature_selection(n=-1)\n",
    "# if you want to use precomputed cross_nmi of the MP. This saves time :\n",
    "# data.feature_selection(n=-1, use_precomputed_cross_nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODNetModel([[['gap_expt_eV']]],\n",
    "                    weights={'gap_expt_eV':1},\n",
    "                    num_neurons = [[256], [128], [16], [16]],\n",
    "                    n_feat = 150,\n",
    "                    act =  \"elu\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1403 - mae: 1.1403 - val_loss: 1.1806 - val_mae: 1.1806\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9577 - mae: 0.9577 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8267 - mae: 0.8267 - val_loss: 0.5956 - val_mae: 0.5956\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7825 - mae: 0.7825 - val_loss: 0.5075 - val_mae: 0.5075\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7321 - mae: 0.7321 - val_loss: 0.4663 - val_mae: 0.4663\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6460 - mae: 0.6460 - val_loss: 0.4526 - val_mae: 0.4526\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6106 - mae: 0.6106 - val_loss: 0.4397 - val_mae: 0.4397\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6307 - mae: 0.6307 - val_loss: 0.4066 - val_mae: 0.4066\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6335 - mae: 0.6335 - val_loss: 0.3399 - val_mae: 0.3399\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6024 - mae: 0.6024 - val_loss: 0.3611 - val_mae: 0.3611\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5935 - mae: 0.5935 - val_loss: 0.3748 - val_mae: 0.3748\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6024 - mae: 0.6024 - val_loss: 0.3613 - val_mae: 0.3613\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5872 - mae: 0.5872 - val_loss: 0.3380 - val_mae: 0.3380\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5521 - mae: 0.5521 - val_loss: 0.3084 - val_mae: 0.3084\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5124 - mae: 0.5124 - val_loss: 0.3470 - val_mae: 0.3470\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5071 - mae: 0.5071 - val_loss: 0.3885 - val_mae: 0.3885\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5099 - mae: 0.5099 - val_loss: 0.3749 - val_mae: 0.3749\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5000 - mae: 0.5000 - val_loss: 0.3229 - val_mae: 0.3229\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4938 - mae: 0.4938 - val_loss: 0.2932 - val_mae: 0.2932\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4896 - mae: 0.4896 - val_loss: 0.2916 - val_mae: 0.2916\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4728 - mae: 0.4728 - val_loss: 0.3292 - val_mae: 0.3292\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4632 - mae: 0.4632 - val_loss: 0.3369 - val_mae: 0.3369\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4573 - mae: 0.4573 - val_loss: 0.3149 - val_mae: 0.3149\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4447 - mae: 0.4447 - val_loss: 0.3194 - val_mae: 0.3194\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4426 - mae: 0.4426 - val_loss: 0.3206 - val_mae: 0.3206\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4319 - mae: 0.4319 - val_loss: 0.3186 - val_mae: 0.3186\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4270 - mae: 0.4270 - val_loss: 0.3013 - val_mae: 0.3013\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4189 - mae: 0.4189 - val_loss: 0.2897 - val_mae: 0.2897\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4151 - mae: 0.4151 - val_loss: 0.3195 - val_mae: 0.3195\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4068 - mae: 0.4068 - val_loss: 0.3268 - val_mae: 0.3268\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4006 - mae: 0.4006 - val_loss: 0.3174 - val_mae: 0.3174\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3943 - mae: 0.3943 - val_loss: 0.2972 - val_mae: 0.2972\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3893 - mae: 0.3893 - val_loss: 0.2909 - val_mae: 0.2909\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4032 - mae: 0.4032 - val_loss: 0.3035 - val_mae: 0.3035\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3910 - mae: 0.3910 - val_loss: 0.3518 - val_mae: 0.3518\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4157 - mae: 0.4157 - val_loss: 0.3268 - val_mae: 0.3268\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3787 - mae: 0.3787 - val_loss: 0.2772 - val_mae: 0.2772\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4021 - mae: 0.4021 - val_loss: 0.2739 - val_mae: 0.2739\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3857 - mae: 0.3857 - val_loss: 0.3349 - val_mae: 0.3349\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3699 - mae: 0.3699 - val_loss: 0.3300 - val_mae: 0.3300\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3686 - mae: 0.3686 - val_loss: 0.2848 - val_mae: 0.2848\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3618 - mae: 0.3618 - val_loss: 0.2708 - val_mae: 0.2708\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3633 - mae: 0.3633 - val_loss: 0.2664 - val_mae: 0.2664\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3563 - mae: 0.3563 - val_loss: 0.2749 - val_mae: 0.2749\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3504 - mae: 0.3504 - val_loss: 0.3002 - val_mae: 0.3002\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3551 - mae: 0.3551 - val_loss: 0.2617 - val_mae: 0.2617\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3462 - mae: 0.3462 - val_loss: 0.2476 - val_mae: 0.2476\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3529 - mae: 0.3529 - val_loss: 0.2612 - val_mae: 0.2612\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3468 - mae: 0.3468 - val_loss: 0.2711 - val_mae: 0.2711\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3432 - mae: 0.3432 - val_loss: 0.2457 - val_mae: 0.2457\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3377 - mae: 0.3377 - val_loss: 0.2663 - val_mae: 0.2663\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3370 - mae: 0.3370 - val_loss: 0.2847 - val_mae: 0.2847\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3323 - mae: 0.3323 - val_loss: 0.2692 - val_mae: 0.2692\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3240 - mae: 0.3240 - val_loss: 0.2706 - val_mae: 0.2706\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3310 - mae: 0.3310 - val_loss: 0.2606 - val_mae: 0.2606\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3298 - mae: 0.3298 - val_loss: 0.2561 - val_mae: 0.2561\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3256 - mae: 0.3256 - val_loss: 0.2406 - val_mae: 0.2406\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3221 - mae: 0.3221 - val_loss: 0.2469 - val_mae: 0.2469\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3148 - mae: 0.3148 - val_loss: 0.2829 - val_mae: 0.2829\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3173 - mae: 0.3173 - val_loss: 0.2982 - val_mae: 0.2982\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3278 - mae: 0.3278 - val_loss: 0.2672 - val_mae: 0.2672\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3147 - mae: 0.3147 - val_loss: 0.2564 - val_mae: 0.2564\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3023 - mae: 0.3023 - val_loss: 0.2661 - val_mae: 0.2661\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3096 - mae: 0.3096 - val_loss: 0.2566 - val_mae: 0.2566\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3074 - mae: 0.3074 - val_loss: 0.2392 - val_mae: 0.2392\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3029 - mae: 0.3029 - val_loss: 0.2391 - val_mae: 0.2391\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2964 - mae: 0.2964 - val_loss: 0.2274 - val_mae: 0.2274\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2932 - mae: 0.2932 - val_loss: 0.2589 - val_mae: 0.2589\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3011 - mae: 0.3011 - val_loss: 0.2981 - val_mae: 0.2981\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2972 - mae: 0.2972 - val_loss: 0.2714 - val_mae: 0.2714\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2911 - mae: 0.2911 - val_loss: 0.2824 - val_mae: 0.2824\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2844 - mae: 0.2844 - val_loss: 0.2689 - val_mae: 0.2689\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2867 - mae: 0.2867 - val_loss: 0.2735 - val_mae: 0.2735\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2851 - mae: 0.2851 - val_loss: 0.2878 - val_mae: 0.2878\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2804 - mae: 0.2804 - val_loss: 0.2580 - val_mae: 0.2580\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2808 - mae: 0.2808 - val_loss: 0.2448 - val_mae: 0.2448\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2887 - mae: 0.2887 - val_loss: 0.2720 - val_mae: 0.2720\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2816 - mae: 0.2816 - val_loss: 0.2942 - val_mae: 0.2942\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2792 - mae: 0.2792 - val_loss: 0.2699 - val_mae: 0.2699\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2739 - mae: 0.2739 - val_loss: 0.2697 - val_mae: 0.2697\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2687 - mae: 0.2687 - val_loss: 0.3203 - val_mae: 0.3203\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2759 - mae: 0.2759 - val_loss: 0.2798 - val_mae: 0.2798\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2658 - mae: 0.2658 - val_loss: 0.2865 - val_mae: 0.2865\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2585 - mae: 0.2585 - val_loss: 0.3228 - val_mae: 0.3228\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2633 - mae: 0.2633 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2666 - mae: 0.2666 - val_loss: 0.3036 - val_mae: 0.3036\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2562 - mae: 0.2562 - val_loss: 0.3094 - val_mae: 0.3094\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2571 - mae: 0.2571 - val_loss: 0.2702 - val_mae: 0.2702\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2718 - mae: 0.2718 - val_loss: 0.2917 - val_mae: 0.2917\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2505 - mae: 0.2505 - val_loss: 0.2882 - val_mae: 0.2882\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2457 - mae: 0.2457 - val_loss: 0.3332 - val_mae: 0.3332\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2543 - mae: 0.2543 - val_loss: 0.3210 - val_mae: 0.3210\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2558 - mae: 0.2558 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2489 - mae: 0.2489 - val_loss: 0.3592 - val_mae: 0.3592\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2620 - mae: 0.2620 - val_loss: 0.3163 - val_mae: 0.3163\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2490 - mae: 0.2490 - val_loss: 0.2647 - val_mae: 0.2647\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2740 - mae: 0.2740 - val_loss: 0.3148 - val_mae: 0.3148\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.3308 - val_mae: 0.3308\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2458 - mae: 0.2458 - val_loss: 0.3030 - val_mae: 0.3030\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2369 - mae: 0.2369 - val_loss: 0.3392 - val_mae: 0.3392\n"
     ]
    }
   ],
   "source": [
    "model.fit(train,\n",
    "          val_fraction = 0.1,\n",
    "          lr = 0.0002,\n",
    "          batch_size = 64,\n",
    "          loss = 'mae',\n",
    "          epochs = 100,\n",
    "          verbose = 1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap_expt_eV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id40</th>\n",
       "      <td>-0.508559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id35</th>\n",
       "      <td>2.871215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id81</th>\n",
       "      <td>-0.570688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id61</th>\n",
       "      <td>1.950733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id98</th>\n",
       "      <td>2.004308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gap_expt_eV\n",
       "id40    -0.508559\n",
       "id35     2.871215\n",
       "id81    -0.570688\n",
       "id61     1.950733\n",
       "id98     2.004308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.3859002037048341\n"
     ]
    }
   ],
   "source": [
    "mae_test = np.absolute(pred.values-test.df_targets.values).mean()\n",
    "print(f'mae: {mae_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modnet-develop]",
   "language": "python",
   "name": "conda-env-modnet-develop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
